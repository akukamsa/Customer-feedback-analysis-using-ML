{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'complaint', 'bug', 'meaningless', 'comment', 'request', 'undefined'}\n"
     ]
    }
   ],
   "source": [
    "st=[]\n",
    "with open('stopwords.txt','r') as stopwords:\n",
    "    for i in stopwords:\n",
    "        st.append(i.strip())\n",
    "#print(st)\n",
    "with open(\"en-training.txt\") as f: \n",
    "    data = f.readlines()\n",
    "#print(data)\n",
    "changed_data=[]\n",
    "data_result=[]\n",
    "data_list=[]\n",
    "for txt in data[:]:\n",
    "    lst=txt.strip().split()\n",
    "    #print(lst)\n",
    "    list1=[]\n",
    "    complete_txt=\"\"\n",
    "    if(len(lst)>1):\n",
    "        data_result.append(lst[-1].lower())\n",
    "        for i in range(1,len(lst)-1):\n",
    "            for j in lst[i].split(','):\n",
    "                if j.lower() not in st and len(j)>1:\n",
    "                    complete_txt=complete_txt+j.lower()+' '\n",
    "                    list1.append(j.lower())\n",
    "            #print(lst[i])\n",
    "        changed_data.append(complete_txt)\n",
    "        data_list.append(list1)\n",
    "        #print(i)\n",
    "#print(changed_data)\n",
    "#print(data_result)\n",
    "#print(data_list)\n",
    "result_set=set(data_result)\n",
    "res=list(result_set)\n",
    "print(result_set)\n",
    "#print(len(data_result))\n",
    "#print(len(data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "freqwords=defaultdict(int)\n",
    "for words in data_list:\n",
    "    for word in words:\n",
    "        freqwords[word]=freqwords[word]+1\n",
    "#freqwords\n",
    "abc=freqwords.copy()\n",
    "for j in abc:\n",
    "    if freqwords[j]==1:\n",
    "        freqwords.pop(j)\n",
    "#freqwords\n",
    "#print(freqwords)\n",
    "filtdata=[]\n",
    "for datas in data_list:\n",
    "    filt=[]\n",
    "    for word in datas:\n",
    "        if freqwords[word]>1:\n",
    "            filt.append(word)\n",
    "    filtdata.append(filt)\n",
    "#print(filtdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "dictbow=gensim.corpora.Dictionary(filtdata)\n",
    "bowdata=[dictbow.doc2bow(mail) for mail in filtdata]\n",
    "dense_bow = gensim.matutils.corpus2dense(bowdata, num_terms=len(dictbow)).transpose()\n",
    "dense_bow.shape\n",
    "\n",
    "tfidf=gensim.models.TfidfModel(bowdata)\n",
    "records=tfidf[bowdata]\n",
    "dense_tfidf=gensim.matutils.corpus2dense(records,num_terms=len(dictbow)).transpose()\n",
    "dataset=dense_tfidf\n",
    "#dataset.shape\n",
    "target=[]\n",
    "for i in data_result:\n",
    "    if i == res[0]:\n",
    "        target.append(5)\n",
    "    if i == res[1]:\n",
    "        target.append(4)\n",
    "    if i == res[2]:\n",
    "        target.append(0)\n",
    "    if i == res[3]:\n",
    "        target.append(3)\n",
    "    if i == res[4]:\n",
    "        target.append(1)\n",
    "    else:\n",
    "        target.append(2)\n",
    "#print(target)\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10,random_state=None,shuffle=True)\n",
    "kf.get_n_splits(dataset)\n",
    "#print(kf)\n",
    "testid=[]\n",
    "trainid=[]\n",
    "\n",
    "    #print(test_index,train_index)\n",
    "#print(\"trainid\")\n",
    "#print(trainid)\n",
    "#print(\"testid\")\n",
    "#print(testid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm # best  49.42 --->56.89\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB # 47.50  ---->51.96\n",
    "from sklearn.naive_bayes import BernoulliNB  #44.40    --->49.34\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier    #43.88 --->5 nearest neighbours\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#for i in trainid:\n",
    "#    for j in i:\n",
    "#        print (j)\n",
    "#for i in range(0,len(trainid)):\n",
    " #   for j in trainid[i]:\n",
    "  #      print(j)\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.527687296416936 0.32277727737836226 0.34527687296416937 0.33316852674979014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash singh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\akash singh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.20195439739413 0.30622579685681406 0.34201954397394135 0.3215213534815529\n",
      "37.45928338762215 0.3564717983884793 0.3745928338762215 0.36229221622117197\n",
      "37.45928338762215 0.3272896801944754 0.3745928338762215 0.34619423659429843\n",
      "38.762214983713356 0.36996233198541106 0.38762214983713356 0.37853131160046244\n",
      "40.19607843137255 0.3727111214856313 0.40196078431372545 0.38516145249941197\n",
      "36.60130718954248 0.3588077768105128 0.3660130718954248 0.3619468673458529\n",
      "34.31372549019608 0.32327229867806057 0.3431372549019608 0.32916666881557505\n",
      "32.35294117647059 0.2871501963682739 0.3235294117647059 0.3016428254811475\n",
      "36.27450980392157 0.336168133002595 0.3627450980392157 0.3439208672870404\n",
      "40.19607843137255\n",
      "0.3727111214856313\n",
      "0.40196078431372545\n",
      "0.38516145249941197\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "psArr=[]\n",
    "rsArr=[]\n",
    "farr=[]\n",
    "for train_index,test_index in kf.split(dataset):\n",
    "   # print(\"train ind {} test index {}\".format(train_index,test_index))\n",
    "    testid.append(test_index)\n",
    "    trainid.append(train_index)\n",
    "    train_set=[]\n",
    "    train_tag=[]\n",
    "    test_set=[]\n",
    "    test_tag=[]\n",
    "    for ind in train_index:\n",
    "        train_set.append(dataset[ind])\n",
    "        train_tag.append(target[ind])\n",
    "    for ind in test_index:\n",
    "        test_set.append(dataset[ind])\n",
    "        test_tag.append(target[ind])\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(train_set,train_tag)\n",
    "    pred=clf.predict(test_set)\n",
    "    incorrect=(pred!=test_tag).sum()\n",
    "    accu=(len(test_set)-incorrect)/len(test_set)*100.0\n",
    "    accuracies.append(accu)\n",
    "    ps=precision_score(test_tag,pred,average=\"weighted\")\n",
    "    rs=recall_score(test_tag,pred,average=\"weighted\")\n",
    "    fscore=f1_score(test_tag,pred,average=\"weighted\")\n",
    "    farr.append(fscore)\n",
    "    psArr.append(ps)\n",
    "    rsArr.append(rs)\n",
    "    print(accu,ps,rs,fscore)\n",
    "print(max(accuracies))\n",
    "print(max(psArr))\n",
    "print(max(rsArr))\n",
    "print(max(farr))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
